{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Compare the results with normal holdout validation\n",
    "- Apply 5-fold cross validation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "This time, let's only include the variables that were previously selected using recursive feature elimination. We included the code to preprocess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "b = boston_features[\"B\"]\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>0.542096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.275260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.263711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.989737</td>\n",
       "      <td>-1.627858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>-2.153192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.162114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE       DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  0.542096  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  0.623954  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  0.623954  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  0.707895  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  0.707895  3.0  222.0   \n",
       "\n",
       "   PTRATIO         B     LSTAT  \n",
       "0     15.3  1.000000 -1.275260  \n",
       "1     17.8  1.000000 -0.263711  \n",
       "2     17.8  0.989737 -1.627858  \n",
       "3     18.7  0.994276 -2.153192  \n",
       "4     18.7  1.000000 -1.162114  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_features[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']]\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Perform a train-test-split with a test set of 0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and apply the model to the make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_residuals = y_hat_train - y_train\n",
    "test_residuals = y_hat_test - y_test\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: let's build it from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function k-folds that splits a dataset into k evenly sized pieces.\n",
    "If the full dataset is not divisible by k, make the first few folds one larger then later ones.\n",
    "\n",
    "We want the folds to be a list of subsets of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boston_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    split = np.array_split(data, k)\n",
    "    subsets = []\n",
    "    for i in range(k):\n",
    "        subset_i = pd.DataFrame(data = split[i])\n",
    "        subsets.append(subset_i)\n",
    "    # Force data as pandas dataframe\n",
    "    # add 1 to fold size to account for leftovers           \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it to the Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to concatenate the data again\n",
    "features_subsets = kfolds(X, 5)\n",
    "target_subsets = kfolds(y, 5)\n",
    "full_subsets = []\n",
    "for i in range(4):\n",
    "    full_subset_i = features_subsets[i].join(target_subsets[i])\n",
    "    full_subsets.append(full_subset_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     CHAS     RM       DIS         B     LSTAT     0\n",
       " 0     0.0  6.575  0.542096  1.000000 -1.275260  24.0\n",
       " 1     0.0  6.421  0.623954  1.000000 -0.263711  21.6\n",
       " 2     0.0  7.185  0.623954  0.989737 -1.627858  34.7\n",
       " 3     0.0  6.998  0.707895  0.994276 -2.153192  33.4\n",
       " 4     0.0  7.147  0.707895  1.000000 -1.162114  36.2\n",
       " 5     0.0  6.430  0.707895  0.992990 -1.200048  28.7\n",
       " 6     0.0  6.012  0.671500  0.996722  0.248456  22.9\n",
       " 7     0.0  6.172  0.700059  1.000000  0.968416  27.1\n",
       " 8     0.0  5.631  0.709276  0.974104  1.712312  16.5\n",
       " 9     0.0  6.004  0.743201  0.974305  0.779802  18.9\n",
       " 10    0.0  6.377  0.727217  0.988956  1.077829  15.0\n",
       " 11    0.0  6.009  0.719175  1.000000  0.357391  18.9\n",
       " 12    0.0  5.889  0.663113  0.983862  0.638571  21.7\n",
       " 13    0.0  5.949  0.601338  1.000000 -0.432353  20.4\n",
       " 14    0.0  6.096  0.578763  0.957436 -0.071152  18.2\n",
       " 15    0.0  5.834  0.582214  0.996772 -0.390531  19.9\n",
       " 16    0.0  5.935  0.582214  0.974658 -0.811149  23.1\n",
       " 17    0.0  5.990  0.559046  0.974406  0.524473  17.5\n",
       " 18    0.0  5.456  0.510723  0.727899  0.146209  20.2\n",
       " 19    0.0  5.727  0.510723  0.984997  0.086734  18.2\n",
       " 20    0.0  5.570  0.510878  0.948737  1.123625  13.6\n",
       " 21    0.0  5.965  0.534015  0.988981  0.426247  19.6\n",
       " 22    0.0  6.142  0.530282  1.000000  0.930584  15.2\n",
       " 23    0.0  5.813  0.542632  0.994049  1.030738  14.5\n",
       " 24    0.0  5.924  0.572839  0.993520  0.699986  15.6\n",
       " 25    0.0  5.599  0.578073  0.764285  0.721311  13.9\n",
       " 26    0.0  5.813  0.599050  0.949518  0.540295  16.6\n",
       " 27    0.0  6.047  0.577960  0.771748  0.797246  14.8\n",
       " 28    0.0  6.495  0.578083  0.977407  0.297319  18.4\n",
       " 29    0.0  6.674  0.557172  0.957966  0.187030  21.0\n",
       " ..    ...    ...       ...       ...       ...   ...\n",
       " 72    0.0  6.065  0.650274  0.984896 -1.103765  22.8\n",
       " 73    0.0  6.245  0.650274  0.950250 -0.584282  23.4\n",
       " 74    0.0  6.273  0.558412  0.995007 -0.761270  24.1\n",
       " 75    0.0  6.286  0.582589  0.965530 -0.300567  21.4\n",
       " 76    0.0  6.279  0.538184  0.941399  0.185639  20.0\n",
       " 77    0.0  6.140  0.542148  0.974936 -0.069529  20.8\n",
       " 78    0.0  6.232  0.627922  0.973524  0.236351  21.2\n",
       " 79    0.0  5.874  0.582589  0.997882 -0.271017  20.3\n",
       " 80    0.0  6.727  0.659214  1.000000 -1.174663  28.0\n",
       " 81    0.0  6.619  0.659214  0.996798 -0.656525  23.9\n",
       " 82    0.0  6.302  0.659214  1.000000 -0.776077  24.8\n",
       " 83    0.0  6.167  0.659214  0.984215 -0.590923  22.9\n",
       " 84    0.0  6.389  0.607724  1.000000 -0.178446  23.9\n",
       " 85    0.0  6.630  0.576472  0.988401 -0.823856  26.6\n",
       " 86    0.0  6.015  0.575474  0.997705  0.305110  22.5\n",
       " 87    0.0  6.121  0.505261  0.995587 -0.396442  22.2\n",
       " 88    0.0  7.007  0.466931  1.000000 -1.109812  23.6\n",
       " 89    0.0  7.079  0.466043  0.997882 -1.050311  28.7\n",
       " 90    0.0  6.417  0.424284  0.988098 -0.324969  22.6\n",
       " 91    0.0  6.405  0.424257  0.991553 -0.444498  22.0\n",
       " 92    0.0  6.442  0.495975  0.995234 -0.452644  22.9\n",
       " 93    0.0  6.211  0.495975  0.998563 -0.907557  25.0\n",
       " 94    0.0  6.249  0.490084  1.000000 -0.018416  20.6\n",
       " 95    0.0  6.625  0.475885  0.901861 -0.793521  28.4\n",
       " 96    0.0  6.163  0.475885  0.987216  0.095571  21.4\n",
       " 97    0.0  8.069  0.475885  1.000000 -1.555067  38.7\n",
       " 98    0.0  7.820  0.475885  0.991502 -1.829759  43.8\n",
       " 99    0.0  7.416  0.475885  1.000000 -0.912931  33.2\n",
       " 100   0.0  6.727  0.379096  0.994604 -0.213444  27.5\n",
       " 101   0.0  6.781  0.390808  0.996672 -0.555806  26.5\n",
       " \n",
       " [102 rows x 6 columns],      CHAS     RM       DIS         B     LSTAT   0\n",
       " 102   0.0  6.405  0.369415  0.177720 -0.012136 NaN\n",
       " 103   0.0  6.137  0.369415  0.993873  0.378596 NaN\n",
       " 104   0.0  6.167  0.321174  0.989384  0.235000 NaN\n",
       " 105   0.0  5.851  0.262627  0.992814  0.717270 NaN\n",
       " 106   0.0  5.836  0.282946  0.996898  0.925237 NaN\n",
       " 107   0.0  6.127  0.265716  0.976776  0.457274 NaN\n",
       " 108   0.0  6.474  0.323240  0.995814  0.226874 NaN\n",
       " 109   0.0  6.229  0.342236  0.985703  0.621518 NaN\n",
       " 110   0.0  6.195  0.379096  0.991401  0.323147 NaN\n",
       " 111   0.0  6.715  0.363602  0.996697 -0.087468 NaN\n",
       " 112   0.0  5.913  0.309243  0.995083  0.690763 NaN\n",
       " 113   0.0  6.092  0.342715  1.000000  0.778828 NaN\n",
       " 114   0.0  6.254  0.291528  0.979424 -0.040585 NaN\n",
       " 115   0.0  5.928  0.328438  0.868904  0.643864 NaN\n",
       " 116   0.0  6.176  0.371798  0.990922  0.195352 NaN\n",
       " 117   0.0  6.021  0.374460  0.993973 -0.064670 NaN\n",
       " 118   0.0  5.872  0.330894  0.853069  0.602122 NaN\n",
       " 119   0.0  5.731  0.376265  0.986384  0.399535 NaN\n",
       " 120   0.0  5.870  0.291752  0.980458  0.490053 NaN\n",
       " 121   0.0  6.004  0.280347  0.951510  0.478420 NaN\n",
       " 122   0.0  5.961  0.258609  0.952569  0.858758 NaN\n",
       " 123   0.0  5.856  0.228811  0.932952  1.439583 NaN\n",
       " 124   0.0  5.879  0.242015  0.955822  0.825919 NaN\n",
       " 125   0.0  5.986  0.239191  0.970044  0.540295 NaN\n",
       " 126   0.0  5.613  0.186161  0.905164  1.556654 NaN\n",
       " 127   0.0  5.693  0.193552  0.987922  0.788547 NaN\n",
       " 128   0.0  6.431  0.199215  1.000000  0.604289 NaN\n",
       " 129   0.0  5.637  0.236434  1.000000  0.896421 NaN\n",
       " 130   0.0  6.458  0.264941  0.995310  0.271085 NaN\n",
       " 131   0.0  6.326  0.294227  1.000000  0.225516 NaN\n",
       " ..    ...    ...       ...       ...       ...  ..\n",
       " 173   0.0  6.416  0.358664  0.996470 -0.282037 NaN\n",
       " 174   0.0  5.859  0.367424  0.990746 -0.174987 NaN\n",
       " 175   0.0  6.546  0.429699  0.985022 -1.162114 NaN\n",
       " 176   0.0  6.020  0.483020  0.990746 -0.095686 NaN\n",
       " 177   0.0  6.315  0.453901  0.996722 -0.886234 NaN\n",
       " 178   0.0  6.860  0.399451  0.985804 -0.727222 NaN\n",
       " 179   0.0  6.980  0.386791  1.000000 -1.255310 NaN\n",
       " 180   0.0  7.765  0.373477  0.996621 -0.579869 NaN\n",
       " 181   0.0  6.144  0.350887  1.000000 -0.208148 NaN\n",
       " 182   0.0  7.155  0.367221  0.992990 -1.329660 NaN\n",
       " 183   0.0  6.563  0.389463  1.000000 -1.056167 NaN\n",
       " 184   0.0  5.604  0.409815  0.985123  0.444218 NaN\n",
       " 185   0.0  6.153  0.449073  0.975314  0.342258 NaN\n",
       " 186   0.0  7.831  0.438603  0.989233 -1.462710 NaN\n",
       " 187   0.0  6.782  0.509845  0.992360 -0.786023 NaN\n",
       " 188   0.0  6.556  0.588544  0.964547 -1.422033 NaN\n",
       " 189   0.0  7.185  0.588544  1.000000 -1.143466 NaN\n",
       " 190   0.0  6.951  0.735961  0.951536 -1.235596 NaN\n",
       " 191   0.0  6.739  0.735961  0.981870 -1.375206 NaN\n",
       " 192   0.0  7.178  0.735961  0.983837 -2.193335 NaN\n",
       " 193   0.0  6.800  0.718694  0.991099 -1.258618 NaN\n",
       " 194   0.0  6.604  0.718694  0.949065 -1.489123 NaN\n",
       " 195   0.0  7.875  0.678108  0.993267 -2.136280 NaN\n",
       " 196   0.0  7.287  0.786695  1.000000 -1.607317 NaN\n",
       " 197   0.0  7.107  0.786695  0.892607 -0.363221 NaN\n",
       " 198   0.0  7.274  0.786695  0.988149 -0.801053 NaN\n",
       " 199   0.0  6.975  0.806093  1.000000 -1.422033 NaN\n",
       " 200   0.0  7.135  0.806093  0.968228 -1.462710 NaN\n",
       " 201   0.0  6.162  0.722095  0.992108 -0.608764 NaN\n",
       " 202   0.0  7.610  0.722095  0.996167 -2.059550 NaN\n",
       " \n",
       " [101 rows x 6 columns],      CHAS     RM       DIS         B     LSTAT   0\n",
       " 203   0.0  7.853  0.636563  0.989611 -1.721374 NaN\n",
       " 204   0.0  8.034  0.636563  0.983988 -2.187541 NaN\n",
       " 205   0.0  5.891  0.526931  1.000000  0.025057 NaN\n",
       " 206   0.0  6.326  0.568536  0.994881  0.040312 NaN\n",
       " 207   0.0  5.783  0.568536  0.981164  0.870793 NaN\n",
       " 208   1.0  6.064  0.557192  0.960714  0.523337 NaN\n",
       " 209   1.0  5.344  0.519346  1.000000  1.280090 NaN\n",
       " 210   1.0  5.960  0.519574  0.990796  0.796282 NaN\n",
       " 211   1.0  5.404  0.495871  0.995814  1.343093 NaN\n",
       " 212   1.0  5.807  0.494443  0.984972  0.672162 NaN\n",
       " 213   0.0  6.375  0.526931  0.972036 -0.220533 NaN\n",
       " 214   0.0  5.412  0.486866  0.879041  1.691026 NaN\n",
       " 215   0.0  6.182  0.526931  0.991755 -0.204626 NaN\n",
       " 216   1.0  5.888  0.426973  0.989662  0.387250 NaN\n",
       " 217   0.0  6.642  0.466857  0.989611 -0.166369 NaN\n",
       " 218   1.0  5.951  0.395677  1.000000  0.857829 NaN\n",
       " 219   1.0  6.373  0.459678  0.992032 -0.032634 NaN\n",
       " 220   1.0  6.951  0.391633  0.986888 -0.162934 NaN\n",
       " 221   1.0  6.164  0.418205  0.995814  1.158135 NaN\n",
       " 222   1.0  6.879  0.448096  0.983585 -0.125612 NaN\n",
       " 223   0.0  6.618  0.448096  1.000000 -0.571079 NaN\n",
       " 224   0.0  8.266  0.396420  0.970120 -1.582998 NaN\n",
       " 225   0.0  8.725  0.396420  0.962429 -1.396655 NaN\n",
       " 226   0.0  8.040  0.440770  0.975995 -2.048872 NaN\n",
       " 227   0.0  7.163  0.440770  0.937415 -0.867798 NaN\n",
       " 228   0.0  7.686  0.461153  0.951107 -1.673960 NaN\n",
       " 229   0.0  6.552  0.461153  0.958243 -1.743380 NaN\n",
       " 230   0.0  5.981  0.496618  0.953225  0.140499 NaN\n",
       " 231   0.0  7.412  0.496618  0.947652 -1.187307 NaN\n",
       " 232   0.0  8.337  0.515347  0.972288 -2.443368 NaN\n",
       " ..    ...    ...       ...       ...       ...  ..\n",
       " 274   1.0  6.758  0.540817  1.000000 -1.848530 NaN\n",
       " 275   0.0  6.854  0.559975  1.000000 -2.130681 NaN\n",
       " 276   1.0  7.267  0.608411  0.980710 -0.951040 NaN\n",
       " 277   1.0  6.826  0.615013  0.991301 -1.574970 NaN\n",
       " 278   0.0  6.482  0.547246  1.000000 -0.663461 NaN\n",
       " 279   0.0  6.812  0.543197  1.000000 -1.319324 NaN\n",
       " 280   0.0  7.820  0.600191  0.975818 -1.743380 NaN\n",
       " 281   0.0  6.968  0.646866  0.988224 -1.411109 NaN\n",
       " 282   1.0  7.645  0.644222  0.949997 -2.113994 NaN\n",
       " 283   1.0  7.923  0.695396  0.996520 -2.032981 NaN\n",
       " 284   0.0  7.088  0.786597  0.994503 -0.517163 NaN\n",
       " 285   0.0  6.453  0.786597  0.994503 -0.438415 NaN\n",
       " 286   0.0  6.230  0.878533  0.860558  0.314153 NaN\n",
       " 287   0.0  6.209  0.787167  1.000000 -0.675086 NaN\n",
       " 288   0.0  6.315  0.787167  1.000000 -0.571079 NaN\n",
       " 289   0.0  6.565  0.787167  0.936507 -0.197604 NaN\n",
       " 290   0.0  6.861  0.636456  1.000000 -1.945691 NaN\n",
       " 291   0.0  7.148  0.636456  1.000000 -1.834432 NaN\n",
       " 292   0.0  6.630  0.636456  1.000000 -1.371658 NaN\n",
       " 293   0.0  6.127  0.667097  1.000000 -0.369036 NaN\n",
       " 294   0.0  6.009  0.667097  1.000000 -0.048575 NaN\n",
       " 295   0.0  6.678  0.700760  1.000000 -0.891540 NaN\n",
       " 296   0.0  6.549  0.700760  0.989788 -0.617756 NaN\n",
       " 297   0.0  5.790  0.725441  1.000000  0.652299 NaN\n",
       " 298   0.0  6.345  0.815586  0.927732 -1.278609 NaN\n",
       " 299   0.0  7.041  0.815586  0.936154 -1.357541 NaN\n",
       " 300   0.0  6.871  0.815586  0.984770 -0.945542 NaN\n",
       " 301   0.0  6.590  0.666254  0.997100 -0.199357 NaN\n",
       " 302   0.0  6.495  0.666254  0.966488 -0.351653 NaN\n",
       " 303   0.0  6.982  0.666254  0.983686 -1.315893 NaN\n",
       " \n",
       " [101 rows x 6 columns],      CHAS     RM       DIS         B     LSTAT   0\n",
       " 304   0.0  7.236  0.535033  0.991881 -0.724816 NaN\n",
       " 305   0.0  6.616  0.460516  0.991074 -0.302431 NaN\n",
       " 306   0.0  7.420  0.425223  1.000000 -0.839233 NaN\n",
       " 307   0.0  6.849  0.436424  1.000000 -0.586493 NaN\n",
       " 308   0.0  6.635  0.453901  1.000000 -1.429355 NaN\n",
       " 309   0.0  5.972  0.425672  0.998336 -0.118915 NaN\n",
       " 310   0.0  4.973  0.337960  0.882874  0.276365 NaN\n",
       " 311   0.0  6.122  0.357707  1.000000 -0.970427 NaN\n",
       " 312   0.0  6.023  0.387535  0.998487  0.150478 NaN\n",
       " 313   0.0  6.266  0.446897  0.991149 -0.506586 NaN\n",
       " 314   0.0  6.567  0.488601  0.996949 -0.238388 NaN\n",
       " 315   0.0  5.705  0.526888  0.998790  0.118911 NaN\n",
       " 316   0.0  5.914  0.532574  0.984366  0.895513 NaN\n",
       " 317   0.0  5.782  0.536047  1.000000  0.662782 NaN\n",
       " 318   0.0  6.382  0.480357  0.995739 -0.054994 NaN\n",
       " 319   0.0  6.113  0.532922  0.998311  0.288184 NaN\n",
       " 320   0.0  6.426  0.586111  1.000000 -0.661146 NaN\n",
       " 321   0.0  6.376  0.586111  1.000000 -0.739302 NaN\n",
       " 322   0.0  6.041  0.602553  1.000000 -0.549303 NaN\n",
       " 323   0.0  5.708  0.602553  0.985451  0.153318 NaN\n",
       " 324   0.0  6.415  0.602553  1.000000 -0.931877 NaN\n",
       " 325   0.0  6.431  0.660399  0.991881 -1.242141 NaN\n",
       " 326   0.0  6.312  0.660399  1.000000 -0.923731 NaN\n",
       " 327   0.0  6.083  0.660399  1.000000  0.296017 NaN\n",
       " 328   0.0  5.868  0.644441  0.963538 -0.118915 NaN\n",
       " 329   0.0  6.333  0.644441  0.945307 -0.629066 NaN\n",
       " 330   0.0  6.144  0.694579  0.928564 -0.272849 NaN\n",
       " 331   0.0  5.706  0.746295  0.992738  0.248456 NaN\n",
       " 332   0.0  6.031  0.746295  0.912628 -0.521413 NaN\n",
       " 333   0.0  6.316  0.734568  0.981870 -1.056167 NaN\n",
       " ..    ...    ...       ...       ...       ...  ..\n",
       " 375   0.0  7.313  0.064445  1.000000  0.378596 NaN\n",
       " 376   0.0  6.649  0.073501  0.914570  1.290877 NaN\n",
       " 377   0.0  6.794  0.077585  1.000000  1.140970 NaN\n",
       " 378   0.0  6.380  0.086214  1.000000  1.322824 NaN\n",
       " 379   0.0  6.223  0.086214  0.992032  1.182792 NaN\n",
       " 380   0.0  6.968  0.095354  1.000000  0.790484 NaN\n",
       " 381   0.0  6.545  0.124844  1.000000  1.128374 NaN\n",
       " 382   0.0  5.536  0.141483  1.000000  1.316484 NaN\n",
       " 383   0.0  5.520  0.128681  1.000000  1.382905 NaN\n",
       " 384   0.0  4.368  0.102140  0.719930  1.750824 NaN\n",
       " 385   0.0  5.277  0.098200  1.000000  1.760585 NaN\n",
       " 386   0.0  4.652  0.110170  1.000000  1.617848 NaN\n",
       " 387   0.0  5.000  0.124622  1.000000  1.823194 NaN\n",
       " 388   0.0  4.880  0.143902  0.939533  1.750280 NaN\n",
       " 389   0.0  5.390  0.179125  1.000000  1.110098 NaN\n",
       " 390   0.0  5.713  0.224915  0.993772  0.780776 NaN\n",
       " 391   0.0  6.051  0.274633  0.953301  0.934140 NaN\n",
       " 392   0.0  5.036  0.189219  1.000000  1.457190 NaN\n",
       " 393   0.0  6.193  0.194235  1.000000  0.580304 NaN\n",
       " 394   0.0  5.887  0.192089  1.000000  0.705089 NaN\n",
       " 395   0.0  6.471  0.178540  0.987594  0.781750 NaN\n",
       " 396   0.0  6.405  0.166429  1.000000  0.987445 NaN\n",
       " 397   0.0  5.747  0.155380  0.990418  1.034086 NaN\n",
       " 398   0.0  5.453  0.116554  1.000000  1.748647 NaN\n",
       " 399   0.0  5.852  0.119597  0.851884  1.714537 NaN\n",
       " 400   0.0  5.987  0.143717  1.000000  1.526438 NaN\n",
       " 401   0.0  6.343  0.139800  1.000000  1.067205 NaN\n",
       " 402   0.0  6.404  0.156822  0.947577  1.066385 NaN\n",
       " 403   0.0  5.349  0.172911  1.000000  1.021495 NaN\n",
       " 404   0.0  5.531  0.148620  0.829946  1.563971 NaN\n",
       " \n",
       " [101 rows x 6 columns]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.concat((features_subsets[1],target_subsets[1]), join = 'outer', axis = 1)\n",
    "#features_subsets[1].join(target_)\n",
    "#features_subsets[0].join(target_subsets[0])\n",
    "\n",
    "full_subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a linear regression for each fold, and calculate the training and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regression on each and calculate the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[            0\n",
      "43  -1.031472\n",
      "72   1.045066\n",
      "27   1.621388\n",
      "66   0.233017\n",
      "75   1.397073\n",
      "5   -1.911343\n",
      "54  -0.113291\n",
      "37  -0.876753\n",
      "97  -0.576112\n",
      "23   1.712297\n",
      "77   0.372383\n",
      "32  -1.415051\n",
      "15   0.402404\n",
      "4   -4.644195\n",
      "6   -2.864289\n",
      "88   6.190224\n",
      "2   -1.976567\n",
      "16  -1.200619\n",
      "38  -4.552555\n",
      "71  -1.482308\n",
      "61   2.888790\n",
      "85   0.101711\n",
      "48  -2.429427\n",
      "22   3.505368\n",
      "99  -1.172293\n",
      "47   1.668101\n",
      "12  -3.678859\n",
      "52   2.478061\n",
      "68  -0.177479\n",
      "28   4.292538\n",
      "..        ...\n",
      "10   5.343063\n",
      "98  -6.687296\n",
      "63   1.694536\n",
      "57  -0.636498\n",
      "8   -3.046105\n",
      "45  -0.669183\n",
      "83   0.272354\n",
      "93  -1.015030\n",
      "20   0.219746\n",
      "56   1.883338\n",
      "82  -0.078756\n",
      "24   2.323959\n",
      "3   -0.238573\n",
      "33   1.779654\n",
      "86  -2.860848\n",
      "84  -0.345330\n",
      "74   0.052838\n",
      "44   0.282148\n",
      "36  -1.753203\n",
      "42  -1.070565\n",
      "46  -2.130206\n",
      "70   0.954587\n",
      "14   2.622293\n",
      "35   1.148739\n",
      "49  -3.154432\n",
      "100 -2.290181\n",
      "95  -2.911907\n",
      "73  -0.067065\n",
      "92   1.381398\n",
      "76   1.093425\n",
      "\n",
      "[81 rows x 1 columns],             0\n",
      "64  -5.028918\n",
      "54  -1.893229\n",
      "68   0.713589\n",
      "9    5.100333\n",
      "22  -0.624315\n",
      "97  -1.314648\n",
      "44  -0.777275\n",
      "11   0.761596\n",
      "86   2.120242\n",
      "29   4.538553\n",
      "20  -2.053545\n",
      "17  -0.677187\n",
      "2    2.681132\n",
      "71   3.271890\n",
      "1    2.274894\n",
      "59  -1.498085\n",
      "12   6.390751\n",
      "69   1.366045\n",
      "30   2.051423\n",
      "21  -2.400352\n",
      "7    1.709934\n",
      "32  -0.121739\n",
      "75   4.015636\n",
      "31   0.269724\n",
      "56   3.566686\n",
      "25   1.376456\n",
      "96  -2.037351\n",
      "99   0.358964\n",
      "40  -1.441808\n",
      "93  -5.929738\n",
      "..        ...\n",
      "90   2.795707\n",
      "83  -8.337743\n",
      "94   3.461770\n",
      "4   -2.154023\n",
      "79 -11.482141\n",
      "60  -0.922707\n",
      "38   4.226702\n",
      "5    1.276556\n",
      "45  -6.234237\n",
      "14   1.529193\n",
      "46  -7.907665\n",
      "27   2.147239\n",
      "13   0.109119\n",
      "76   1.913021\n",
      "92   2.576654\n",
      "89   1.590595\n",
      "91   0.979451\n",
      "36   3.776136\n",
      "33   3.551380\n",
      "6    5.132937\n",
      "88  -4.330128\n",
      "26   5.553463\n",
      "42  -3.233776\n",
      "62  -1.536073\n",
      "41  -2.453370\n",
      "55  -4.692451\n",
      "34   1.571932\n",
      "78  -2.344300\n",
      "16  -2.263110\n",
      "72  -0.142799\n",
      "\n",
      "[80 rows x 1 columns],             0\n",
      "56   3.517681\n",
      "59  -2.198963\n",
      "13  -1.841351\n",
      "81  -1.735434\n",
      "69   3.846106\n",
      "65  -3.450785\n",
      "18   0.705179\n",
      "87   4.223040\n",
      "8   -4.333254\n",
      "62  -1.242264\n",
      "33   2.558080\n",
      "22  -0.843706\n",
      "19   3.043965\n",
      "93  -0.238578\n",
      "63   1.509741\n",
      "21   0.924839\n",
      "47   1.927204\n",
      "4   -3.857643\n",
      "36   3.722754\n",
      "100 -0.983462\n",
      "88  -2.382440\n",
      "78  -3.006020\n",
      "74  -1.610722\n",
      "3    0.530204\n",
      "58  -4.258024\n",
      "43  -3.027477\n",
      "2   -0.881432\n",
      "98   4.758954\n",
      "17   5.052573\n",
      "53  -7.092858\n",
      "..        ...\n",
      "86   0.177419\n",
      "55   1.397788\n",
      "54   0.596271\n",
      "60   5.012369\n",
      "5   -3.124214\n",
      "37   6.122913\n",
      "95   2.408027\n",
      "66   0.097914\n",
      "0   -7.964493\n",
      "9   -2.816827\n",
      "68   0.637198\n",
      "50  -0.617878\n",
      "83  -0.360198\n",
      "23   6.783702\n",
      "52  -2.015128\n",
      "99  -0.389131\n",
      "39   0.671228\n",
      "94  -2.424247\n",
      "12  -0.456287\n",
      "30  -3.581508\n",
      "75  -1.258495\n",
      "51  -0.003769\n",
      "29   5.250029\n",
      "76  -3.173959\n",
      "35   2.661719\n",
      "67  -0.858177\n",
      "89   1.765574\n",
      "28   5.004563\n",
      "34   4.912250\n",
      "10  -2.062686\n",
      "\n",
      "[80 rows x 1 columns],             0\n",
      "10  -2.072195\n",
      "74  -1.027487\n",
      "23  -8.229303\n",
      "99   5.522263\n",
      "78   0.057297\n",
      "70  -8.246125\n",
      "24  -0.735444\n",
      "58   2.938219\n",
      "65  -1.387051\n",
      "36   1.247142\n",
      "61   4.250622\n",
      "29   4.183915\n",
      "26  -0.188070\n",
      "59   7.691312\n",
      "53   2.040267\n",
      "39  -0.787182\n",
      "77   2.534652\n",
      "5    1.153109\n",
      "22   3.010500\n",
      "72  -0.717269\n",
      "2   -4.867232\n",
      "87  -9.651942\n",
      "21   4.610987\n",
      "89   4.056509\n",
      "44  -0.568624\n",
      "34   0.801788\n",
      "81   0.398650\n",
      "83  -0.793806\n",
      "71   6.691095\n",
      "16   0.682424\n",
      "..        ...\n",
      "68 -14.030930\n",
      "0  -10.211937\n",
      "32  -0.935133\n",
      "11   1.452848\n",
      "51   3.371958\n",
      "9    3.422619\n",
      "19  -2.177274\n",
      "93   5.511420\n",
      "92   1.731628\n",
      "82  -1.652035\n",
      "45  -2.694112\n",
      "25   1.124854\n",
      "41  -2.495330\n",
      "6    3.562848\n",
      "46   0.636489\n",
      "13  -7.659232\n",
      "30   2.850727\n",
      "67 -21.355356\n",
      "43  -0.316583\n",
      "31  -0.035649\n",
      "3   -2.312929\n",
      "97   6.627657\n",
      "85   1.357353\n",
      "63   2.795173\n",
      "76   6.786601\n",
      "80   0.879210\n",
      "84  -2.711577\n",
      "12  -7.796930\n",
      "28   2.040859\n",
      "40  -1.368199\n",
      "\n",
      "[80 rows x 1 columns]]\n",
      "[           0\n",
      "41  2.519643\n",
      "60 -0.427962\n",
      "13  0.869757\n",
      "1   2.443964\n",
      "11  0.990293\n",
      "55 -2.291552\n",
      "21 -0.820734\n",
      "78 -0.000022\n",
      "34  0.944291\n",
      "39 -2.172380\n",
      "19 -0.208537\n",
      "87 -0.189838\n",
      "80  0.637029\n",
      "94  1.252084\n",
      "26  0.670597\n",
      "31  4.932825\n",
      "69  0.050706\n",
      "17  1.118055\n",
      "18 -6.595156\n",
      "64 -3.156150\n",
      "62  3.896133,            0\n",
      "53  1.378945\n",
      "73  2.263045\n",
      "52  2.916400\n",
      "85 -1.086361\n",
      "23 -0.968111\n",
      "35  6.963846\n",
      "48  0.658680\n",
      "19  0.204915\n",
      "82 -9.085031\n",
      "24 -2.921177\n",
      "49 -2.205958\n",
      "65 -5.103790\n",
      "66 -0.020825\n",
      "39 -6.570423\n",
      "28  5.768473\n",
      "50 -0.614497\n",
      "63 -2.665866\n",
      "10  0.070774\n",
      "81 -0.917893\n",
      "51 -2.508605\n",
      "61 -1.771483,            0\n",
      "48  2.336021\n",
      "92 -0.040000\n",
      "91 -0.099425\n",
      "71 -0.216669\n",
      "16  3.076784\n",
      "97  4.337741\n",
      "80 -9.080314\n",
      "44  1.146262\n",
      "79 -7.175170\n",
      "6  -5.590795\n",
      "61 -0.272133\n",
      "73  0.753754\n",
      "42 -3.698364\n",
      "96  1.976263\n",
      "57  1.615730\n",
      "90 -0.684616\n",
      "84  0.226773\n",
      "7  -1.250720\n",
      "41 -1.973136\n",
      "11 -9.862259\n",
      "77 -4.884872,             0\n",
      "48  -0.512394\n",
      "96   3.643548\n",
      "55  -3.706930\n",
      "15  -5.109505\n",
      "27  -3.833719\n",
      "52   2.550543\n",
      "38   3.138684\n",
      "91   3.077171\n",
      "60  19.251595\n",
      "50  -0.403824\n",
      "35   0.168742\n",
      "69  -7.007250\n",
      "1   -5.594938\n",
      "88  -0.408202\n",
      "17   2.155105\n",
      "42  -4.853194\n",
      "37  -6.385507\n",
      "56   2.161262\n",
      "7    8.722410\n",
      "98   1.868903\n",
      "33  -1.554659]\n"
     ]
    }
   ],
   "source": [
    "test_errs = []\n",
    "train_errs = []\n",
    "k=5\n",
    "\n",
    "for i in range(k-1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_subsets[i], target_subsets[i], test_size = 0.2)\n",
    "    # Fit a linear regression model\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_hat_train = linreg.predict(X_train)\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    #Evaluate Train and Test Errors\n",
    "    train_residuals = y_hat_train - y_train\n",
    "    test_residuals = y_hat_test - y_test\n",
    "    train_errs.append(train_residuals)\n",
    "    test_errs.append(test_residuals)\n",
    "\n",
    "print(train_errs)\n",
    "print(test_errs)\n",
    "#print(np.mean(train_errs))\n",
    "#print(np.mean(test_errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.55884350861665\n",
      "22.85860308071082\n"
     ]
    }
   ],
   "source": [
    "num = 5\n",
    "train_err = []\n",
    "test_err = []\n",
    "for i in range(num):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_hat_train = linreg.predict(X_train)\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "print(np.mean(train_err))  \n",
    "print(np.mean(test_err))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Now, let's perform 5-fold cross-validation to get the mean squared error through scikit-learn. Let's have a look at the five individual MSEs and explain what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-13.40514492 -17.4440168  -37.03271139 -58.27954385 -26.09798876]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = cross_val_score(linreg, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "print(cv_5_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of the MSE over the 5 cross-validations and compare and contrast with the result from the train-test-split case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-30.451881143540316"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_5_mean = np.mean(cross_val_score(linreg, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "cv_5_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge on k-fold crossvalidation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
